{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "8e4dfbbf-f925-45db-aa0c-0abddedc3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be45d6-d3e7-4ae3-917b-bd1bc9c6fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode = True, max_num_hands = 2, min_detection_confidence = 0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Fonction pour extraire les landmarks d'une image\n",
    "def extract_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Récupérer les landmarks pour chaque main détectée\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])  # Coordonnées X, Y, Z\n",
    "            return landmarks\n",
    "    print(f\"Aucune main détectée pour {image_path}\")\n",
    "    return None\n",
    "\n",
    "# Parcourir les dossiers et extraire les données\n",
    "def process_dataset(dataset_path, output_csv):\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # En-tête du fichier CSV\n",
    "        header = ['label'] + [f'{coord}_{i}' for i in range(21) for coord in ['x', 'y', 'z']]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Parcourir les dossiers\n",
    "        for label in os.listdir(dataset_path):\n",
    "            label_path = os.path.join(dataset_path, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for image_name in os.listdir(label_path):\n",
    "                    image_path = os.path.join(label_path, image_name)\n",
    "                    landmarks = extract_landmarks(image_path)\n",
    "                    if landmarks:\n",
    "                        writer.writerow([label] + landmarks)\n",
    "\n",
    "# Chemins\n",
    "dataset_path = \"Train\" \n",
    "output_csv = \"landmarks.csv\"\n",
    "\n",
    "# Exécution\n",
    "process_dataset(dataset_path, output_csv)\n",
    "print(f\"Données enregistrées dans {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b816de-bdbe-44b0-bc66-0b47ae81e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins pour l'échantillon de test\n",
    "test_dataset_path = \"Test\"\n",
    "test_output_csv = \"test_landmarks.csv\"\n",
    "\n",
    "# Exécution pour l'échantillon de test\n",
    "process_dataset(test_dataset_path, test_output_csv)\n",
    "print(f\"Données enregistrées dans {test_output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "0985753c-bdc8-4cd4-a24a-3b1e3aecc374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label       x_0       y_0           z_0       x_1       y_1       z_1  \\\n",
      "0  ENTER  0.313832  0.764376  2.474214e-07  0.358308  0.734033 -0.026857   \n",
      "1  ENTER  0.650379  0.380406  2.110198e-07  0.603407  0.368063 -0.015487   \n",
      "2  ENTER  0.663164  0.614228  1.384285e-07  0.619237  0.591525 -0.012178   \n",
      "3  ENTER  0.338837  0.690563  3.175797e-07  0.293740  0.682436 -0.011694   \n",
      "4  ENTER  0.716060  0.874130  3.947711e-07  0.661055  0.861623 -0.025433   \n",
      "\n",
      "        x_2       y_2       z_2  ...      z_17      x_18      y_18      z_18  \\\n",
      "0  0.386194  0.675503 -0.038582  ... -0.034137  0.273438  0.577838 -0.052214   \n",
      "1  0.568174  0.318842 -0.020643  ... -0.019743  0.653054  0.199351 -0.029746   \n",
      "2  0.589870  0.539513 -0.016454  ... -0.018273  0.676231  0.433817 -0.025656   \n",
      "3  0.258236  0.642395 -0.017841  ... -0.030567  0.360939  0.508950 -0.041258   \n",
      "4  0.618185  0.820818 -0.042626  ... -0.042167  0.758279  0.681288 -0.056616   \n",
      "\n",
      "       x_19      y_19      z_19      x_20      y_20      z_20  \n",
      "0  0.276770  0.542703 -0.060548  0.280732  0.509659 -0.065162  \n",
      "1  0.645040  0.168978 -0.034041  0.636968  0.142315 -0.036402  \n",
      "2  0.670259  0.404335 -0.027768  0.664124  0.379388 -0.028947  \n",
      "3  0.362803  0.474686 -0.044823  0.364105  0.443628 -0.046718  \n",
      "4  0.759192  0.642951 -0.062403  0.759486  0.607219 -0.065730  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "   label       x_0       y_0           z_0       x_1       y_1       z_1  \\\n",
      "0  ENTER  0.372713  0.992195  4.075158e-07  0.415978  0.971429 -0.018991   \n",
      "1  ENTER  0.218966  0.684899  2.662443e-07  0.267944  0.652957 -0.020444   \n",
      "2  ENTER  0.695835  0.743236  1.200198e-07  0.642324  0.708206 -0.010117   \n",
      "3  ENTER  0.672564  0.667273  1.896680e-07  0.611416  0.630776 -0.015410   \n",
      "4  ENTER  0.558197  0.951038  4.124097e-07  0.499413  0.938858 -0.023143   \n",
      "\n",
      "        x_2       y_2       z_2  ...      z_17      x_18      y_18      z_18  \\\n",
      "0  0.443110  0.917652 -0.027041  ... -0.031439  0.340451  0.803522 -0.047341   \n",
      "1  0.303630  0.585849 -0.023309  ... -0.006866  0.192741  0.467618 -0.015227   \n",
      "2  0.607806  0.640412 -0.013044  ... -0.017123  0.698781  0.503783 -0.022862   \n",
      "3  0.572631  0.555050 -0.021079  ... -0.020881  0.680259  0.403728 -0.028222   \n",
      "4  0.452896  0.888823 -0.036276  ... -0.035082  0.588044  0.699659 -0.046850   \n",
      "\n",
      "       x_19      y_19      z_19      x_20      y_20      z_20  \n",
      "0  0.347853  0.764705 -0.054859  0.354923  0.730493 -0.058574  \n",
      "1  0.200441  0.434989 -0.018998  0.208509  0.406563 -0.021629  \n",
      "2  0.689474  0.467991 -0.023101  0.680382  0.437788 -0.023323  \n",
      "3  0.670619  0.364022 -0.028713  0.660530  0.330148 -0.029113  \n",
      "4  0.586353  0.657341 -0.050868  0.582775  0.619509 -0.053072  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# Charger les données d'entraînement obtenues précédemment\n",
    "data_train = pd.read_csv(\"landmarks.csv\")\n",
    "print(data_train.head())  # Affiche les premières lignes pour vérifier le chargement\n",
    "\n",
    "# Charger les données de test obtenues juste avant\n",
    "data_test = pd.read_csv(\"test_landmarks.csv\")\n",
    "print(data_test.head())  # Affiche les premières lignes pour vérifier le chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "5cc6b5ed-d788-4470-b810-40e88c516c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'entraînement après suppression : (5158, 64)\n",
      "Données de test après suppression : (1833, 64)\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.dropna()  # Supprime les lignes avec des valeurs manquantes\n",
    "print(f\"Données d'entraînement après suppression : {data_train.shape}\")\n",
    "\n",
    "data_test = data_test.dropna()  # Supprime les lignes avec des valeurs manquantes\n",
    "print(f\"Données de test après suppression : {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "7b8f6cc6-297a-4c71-9e44-b81a6e7a92dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label       x_0       y_0       z_0       x_1       y_1       z_1  \\\n",
      "0  ENTER  0.329598  0.679027  0.780843  0.373168  0.673895  0.312188   \n",
      "1  ENTER  0.662875  0.273039  0.747177  0.631281  0.284959  0.485181   \n",
      "2  ENTER  0.675536  0.520269  0.680040  0.647952  0.522444  0.535528   \n",
      "3  ENTER  0.354360  0.600981  0.845729  0.305172  0.619060  0.542895   \n",
      "4  ENTER  0.727917  0.795074  0.917120  0.691990  0.809492  0.333856   \n",
      "\n",
      "        x_2       y_2       z_2  ...      z_17      x_18      y_18      z_18  \\\n",
      "0  0.400932  0.646232  0.410156  ...  0.396241  0.287109  0.586272  0.419299   \n",
      "1  0.590779  0.273370  0.583845  ...  0.524845  0.638448  0.199098  0.583771   \n",
      "2  0.613413  0.504065  0.624400  ...  0.537979  0.659898  0.438945  0.613712   \n",
      "3  0.267443  0.611621  0.610969  ...  0.428137  0.368093  0.515803  0.499499   \n",
      "4  0.642952  0.798148  0.371002  ...  0.324492  0.735834  0.692096  0.387074   \n",
      "\n",
      "       x_19      y_19      z_19      x_20      y_20      z_20  \n",
      "0  0.293212  0.554767  0.417450  0.298603  0.536909  0.410010  \n",
      "1  0.629651  0.173215  0.595646  0.620202  0.166188  0.590835  \n",
      "2  0.652691  0.413501  0.637813  0.644717  0.405440  0.637704  \n",
      "3  0.371809  0.485326  0.523163  0.373870  0.470271  0.525970  \n",
      "4  0.733936  0.657115  0.404984  0.730807  0.635366  0.406437  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "   label       x_0       y_0       z_0       x_1       y_1       z_1  \\\n",
      "0  ENTER  0.376631  0.858356  0.671157  0.389537  0.882544  0.752748   \n",
      "1  ENTER  0.225509  0.526229  0.587608  0.226660  0.543601  0.739969   \n",
      "2  ENTER  0.694237  0.589281  0.501129  0.638577  0.602400  0.830767   \n",
      "3  ENTER  0.671363  0.507179  0.542320  0.604570  0.519993  0.784227   \n",
      "4  ENTER  0.558948  0.813873  0.674052  0.481337  0.847879  0.716240   \n",
      "\n",
      "        x_2       y_2       z_2  ...      z_17      x_18      y_18      z_18  \\\n",
      "0  0.393824  0.905300  0.768855  ...  0.493750  0.334718  0.838029  0.469998   \n",
      "1  0.224196  0.550665  0.790357  ...  0.676078  0.203950  0.470873  0.663827   \n",
      "2  0.594118  0.608982  0.849494  ...  0.599976  0.651949  0.510403  0.617749   \n",
      "3  0.551339  0.517746  0.803205  ...  0.572091  0.635552  0.401039  0.585394   \n",
      "4  0.405725  0.874487  0.715647  ...  0.466713  0.553913  0.724502  0.472964   \n",
      "\n",
      "       x_19      y_19      z_19      x_20      y_20      z_20  \n",
      "0  0.338549  0.768946  0.460210  0.340452  0.735084  0.452077  \n",
      "1  0.210063  0.424798  0.658190  0.214725  0.418304  0.642218  \n",
      "2  0.636309  0.459243  0.635543  0.619926  0.448840  0.633498  \n",
      "3  0.619874  0.350724  0.604560  0.602879  0.343576  0.603703  \n",
      "4  0.546428  0.656882  0.482245  0.536110  0.626550  0.480393  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# Etape de normalisation\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_train = data_train.iloc[:, 1:]  # Exclure la colonne des labels\n",
    "features_test = data_test.iloc[:, 1:] # De même pour l'échantillon de test\n",
    "normalized_features_train = scaler.fit_transform(features_train)\n",
    "normalized_features_test = scaler.fit_transform(features_test)\n",
    "\n",
    "# Remplacer les anciennes données par les données normalisées\n",
    "data_train.iloc[:, 1:] = normalized_features_train\n",
    "print(data_train.head())\n",
    "\n",
    "data_test.iloc[:, 1:] = normalized_features_test\n",
    "print(data_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "e497ff32-e8ab-46d9-a421-14494850781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caractéristiques de l'échantillon d'entraînement (X_train) : (5158, 63), Labels (y_test) : (5158,)\n",
      "Caractéristiques de l'échantillon de test (X_test) : (1833, 63), Labels (y_test) : (1833,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_train.iloc[:, 1:]  # Toutes les colonnes sauf les labels\n",
    "y_train = data_train.iloc[:, 0]   # La colonne des labels\n",
    "print(f\"Caractéristiques de l'échantillon d'entraînement (X_train) : {X_train.shape}, Labels (y_test) : {y_train.shape}\")\n",
    "\n",
    "X_test = data_test.iloc[:, 1:]  # Toutes les colonnes sauf les labels\n",
    "y_test = data_test.iloc[:, 0]   # La colonne des labels\n",
    "print(f\"Caractéristiques de l'échantillon de test (X_test) : {X_test.shape}, Labels (y_test) : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "74721ba8-2f07-4f9e-b4cd-e870c76bf4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(landmarks, noise_level = 0.01):\n",
    "    noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "def scale_landmarks(landmarks, scale_factor = 1.1):\n",
    "    return landmarks * scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "c4677f9f-7a67-4385-857f-01bb31f5fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10316, 63)\n"
     ]
    }
   ],
   "source": [
    "# Appliquer plusieurs augmentations\n",
    "X_train_augmented = []\n",
    "\n",
    "# Parcourir les lignes du DataFrame\n",
    "for i in range(X_train.shape[0]):\n",
    "    original = X_train.iloc[i, :]\n",
    "    augmented = [\n",
    "        add_noise(original),\n",
    "        scale_landmarks(original)\n",
    "    ]\n",
    "    X_train_augmented.extend(augmented)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)  # Convertir en tableau NumPy\n",
    "print(X_train_augmented.shape)  # Vérifier la forme finale des données augmentées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "5be1a4b5-90f9-49a6-a0ea-3b93bf783e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_augmented  # Remplacer les données originales par les augmentées\n",
    "y_train = np.repeat(y_train, 2)  # Adapter les labels (chaque ligne originale a 2 augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "8699c8d9-4f15-4d90-919a-b07139ae97ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de X_train après augmentation : (10316, 63)\n",
      "Forme de y_train après répétition des labels : (10316,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forme de X_train après augmentation : {X_train.shape}\")\n",
    "print(f\"Forme de y_train après répétition des labels : {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "6452d1a3-8a5c-4fcf-b3c8-512229fca68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels encodés : [0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Encoder les labels en nombres entiers\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # Conversion des labels\n",
    "y_test = label_encoder.transform(y_test)  # Même transformation pour les données de test\n",
    "\n",
    "print(f\"Labels encodés : {y_train}\")  # Vérifier les labels transformés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "4738e5ba-1e21-486d-819a-be1edfec14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des données en tenseurs PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Créer des DataLoader pour charger les données par lots\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "d330bac3-c1ea-4fcb-8a1f-fc4570951d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=63, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=4, bias=True)\n",
      "    (5): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Softmax(dim = 1)  # Activation pour la sortie\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialiser le modèle\n",
    "input_size = X_train.shape[1]  # Nombre de caractéristiques\n",
    "num_classes = len(np.unique(y_train))  # Nombre de classes\n",
    "model = MLP(input_size, num_classes)\n",
    "print(model)  # Afficher la structure du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "932427e1-6f0a-460f-ab1b-94c2de62d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Perte adaptée pour la classification multiclasses\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)  # Optimiseur Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "cf96c294-4631-4a41-a0fd-526ec7fc525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1/10, Perte : 1.0034\n",
      "Époque 2/10, Perte : 0.8417\n",
      "Époque 3/10, Perte : 0.8242\n",
      "Époque 4/10, Perte : 0.8157\n",
      "Époque 5/10, Perte : 0.8108\n",
      "Époque 6/10, Perte : 0.8081\n",
      "Époque 7/10, Perte : 0.8051\n",
      "Époque 8/10, Perte : 0.8046\n",
      "Époque 9/10, Perte : 0.8001\n",
      "Époque 10/10, Perte : 0.7980\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mode entraînement\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch = batch\n",
    "\n",
    "        # Réinitialiser les gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass et mise à jour\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Époque {epoch+1}/{num_epochs}, Perte : {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "d0955197-4da2-4c22-ad05-d3b206e74dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur l'ensemble de test : 77.03%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Mode évaluation\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Pas de calcul des gradients\n",
    "    for batch in test_loader:\n",
    "        X_batch, y_batch = batch\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)  # Obtenir la classe prédite\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print(f\"Précision sur l'ensemble de test : {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "b27fb96c-148b-4b58-8ac8-eb7b5854cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "820e54c5-913c-43dc-90b3-d9194e5e946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "7d4c5101-56d6-4fcd-bbe2-dde35430cdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436.0"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train==3)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7aaa9-f7c6-4742-8c89-423f5957c1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
